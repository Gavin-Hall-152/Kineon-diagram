{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d0ba19a-03b6-494a-a53f-312bd151ad0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType\n",
    "\n",
    "def dim_fy_completed(catalog_name):\n",
    "    data = [\n",
    "        ('2036', '2036-01-01', '2036-12-31'),\n",
    "        ('2035', '2035-01-01', '2035-12-31'),\n",
    "        ('2034', '2034-01-01', '2034-12-31'),\n",
    "        ('2033', '2033-01-01', '2033-12-31'),\n",
    "        ('2032', '2032-01-01', '2032-12-31'),\n",
    "        ('2031', '2031-01-01', '2031-12-31'),\n",
    "        ('2030', '2030-01-01', '2030-12-31'),\n",
    "        ('2029', '2029-01-01', '2029-12-31'),\n",
    "        ('2028', '2028-01-01', '2028-12-31'),\n",
    "        ('2027', '2027-01-01', '2027-12-31'),\n",
    "        ('2026', '2026-01-01', '2026-12-31'),\n",
    "        ('2025', '2025-01-01', '2025-12-31'),\n",
    "        ('2024', '2024-01-01', '2024-12-31'),\n",
    "        ('2023', '2023-01-01', '2023-12-31'),\n",
    "        ('2022', '2022-01-01', '2022-12-31'),\n",
    "        ('2021', '2021-01-01', '2021-12-31'),\n",
    "        ('2020', '2020-01-01', '2020-12-31'),\n",
    "        ('2019', '2019-01-01', '2019-12-31'),\n",
    "        ('2018', '2018-01-01', '2018-12-31'),\n",
    "        ('2017', '2017-01-01', '2017-12-31'),\n",
    "        ('2016', '2016-01-01', '2016-12-31'),\n",
    "        ('2015', '2015-01-01', '2015-12-31'),\n",
    "        ('2014', '2014-01-01', '2014-12-31'),\n",
    "        ('2013', '2013-01-01', '2013-12-31'),\n",
    "        ('2012', '2012-01-01', '2012-12-31'),\n",
    "        ('N/A', '1900-01-01', '1900-01-01')\n",
    "    ]\n",
    "\n",
    "    # Schema definition\n",
    "    schema = StructType([\n",
    "        StructField(\"fy_completed\", StringType(), True),\n",
    "        StructField(\"fy_start_date\", StringType(), True),\n",
    "        StructField(\"fy_end_date\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = spark.createDataFrame(data, schema)\n",
    "\n",
    "    # Cast string to DateType\n",
    "    df = df.withColumn(\"fy_start_date\", col(\"fy_start_date\").cast(DateType())) \\\n",
    "           .withColumn(\"fy_end_date\", col(\"fy_end_date\").cast(DateType()))\n",
    "\n",
    "    # Save as Delta table\n",
    "    output_path = f\"{catalog_name}.schema.dim_fy_completed\"\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(output_path)\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "dim_fy_completed",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
